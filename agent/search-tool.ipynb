{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\phi.nguyen\\.conda\\envs\\neurond\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import json\n",
    "from typing import List, Optional\n",
    "\n",
    "# Third-party imports\n",
    "from dotenv import load_dotenv\n",
    "import tiktoken\n",
    "from pprint import pprint\n",
    "\n",
    "# llama-index imports\n",
    "from llama_index.agent.openai import OpenAIAssistantAgent, OpenAIAgent\n",
    "\n",
    "from llama_index.core.agent import ReActAgent\n",
    "\n",
    "from llama_index.core.tools import FunctionTool, ToolMetadata\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "# Local imports\n",
    "from ai_config_schema import LLM\n",
    "from get_llm import get_llm, token_counter, get_llm_azure\n",
    "from web_search import (\n",
    "    get_page_content,\n",
    "    process_search_results,\n",
    "    generate_queries_search_engine,\n",
    ")\n",
    "from llama_index.core.agent.react import ReActChatFormatter\n",
    "from react.custom_formatter import CustomReActChatFormatter\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent with web tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from react.agent_logger import log_step_output\n",
    "import types\n",
    "from react.ReActAgentCustom import ReActAgentCustom\n",
    "from llama_index.core.agent import FunctionCallingAgent\n",
    "from llama_index.core.tools import ToolOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt-4o-mini\"\n",
    "# model_name = \"claude-medium\"\n",
    "\n",
    "\n",
    "def run_agent(\n",
    "    model_name: str,\n",
    "    system_prompt: str,\n",
    "    tools: Optional[List] = None,\n",
    "    history: Optional[List] = None,\n",
    "):\n",
    "    if model_name in [\"gpt-4o-mini\", \"gpt-4-turbo\", \"gpt-4\"]:\n",
    "        agent = OpenAIAgent.from_tools(\n",
    "            tools=tools,\n",
    "            system_prompt=system_prompt,\n",
    "            chat_history=history,\n",
    "            llm=get_llm_azure(),\n",
    "            verbose=True,\n",
    "            context=system_prompt,\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        agent = ReActAgent.from_tools(\n",
    "            tools=tools,\n",
    "            system_prompt=system_prompt,\n",
    "            chat_history=history,\n",
    "            llm=get_llm(model_name),\n",
    "            verbose=True,\n",
    "            context=system_prompt,\n",
    "        )\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from system_prompt import DEFAULT_SYSTEM_PROMPT, DEFAULT_SYSTEM_PROMPT_OPTIMIZED\n",
    "import datetime\n",
    "\n",
    "DEFAULT_SYSTEM_PROMPT_WITH_TIME = DEFAULT_SYSTEM_PROMPT.format(\n",
    "    date=str(datetime.datetime.now().date())\n",
    ")\n",
    "DEFAULT_SYSTEM_PROMPT_OPTIMIZED_WITH_TIME = DEFAULT_SYSTEM_PROMPT_OPTIMIZED.format(\n",
    "    date=str(datetime.datetime.now().date())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure tools\n",
    "web_search_tool = FunctionTool.from_defaults(\n",
    "    fn=process_search_results,\n",
    ")\n",
    "\n",
    "web_fetch_tool = FunctionTool.from_defaults(\n",
    "    fn=get_page_content,\n",
    ")\n",
    "\n",
    "tools = [web_fetch_tool, web_search_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 64a0fe03-6978-46f3-8259-e0a48121b753. Step input: kết quả trận T1 vs BLG mới nhất\n",
      "\u001b[1;3;38;5;200mThought: Tôi cần tìm kiếm thông tin mới nhất về kết quả trận đấu giữa T1 và BLG.\n",
      "Action: web_search_tool\n",
      "Action Input: {'input': 'T1 vs BLG latest match result November 2024'}\n",
      "\u001b[0msub question: ['T1 vs BLG latest match result November 2024']\n",
      "\u001b[1;3;34mObservation: [{'url': 'https://www.gameleap.com/articles/worlds-2024-grand-final-t1-vs-blg-match-results'}, {'url': 'https://escorenews.com/en/lol/world-championship-2024/playoff/bilibili-gaming-vs-t1-571343'}, {'url': 'https://gol.gg/game/stats/62839/page-game/'}]\n",
      "\u001b[0m> Running step c5baaefe-4b53-4de7-995b-d22656c53f4e. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: Tôi đã tìm thấy một số liên kết có thể chứa thông tin về kết quả trận đấu giữa T1 và BLG. Tôi sẽ lấy thông tin từ các liên kết này để cung cấp kết quả chính xác.\n",
      "Action: web_fetch_tool\n",
      "Action Input: {'input': 'https://www.gameleap.com/articles/worlds-2024-grand-final-t1-vs-blg-match-results'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: Worlds 2024 Grand Final T1 vs BLG Match Results\n",
      "Home\n",
      "Courses\n",
      "Videos\n",
      "Guides\n",
      "News\n",
      "Search\n",
      "LOGIN\n",
      "SIGN UP\n",
      "RAID: Shadow Legends\n",
      "League of Legends\n",
      "Metaphor: ReFantazio\n",
      "Roblox\n",
      "World of Warcraft\n",
      "Genshin Impact\n",
      "Fortnite\n",
      "All Categories\n",
      "Login\n",
      "Signup\n",
      "Gaming\n",
      "RAID: Shadow Legends\n",
      "League of Legends\n",
      "Metaphor: ReFantazio\n",
      "Roblox\n",
      "World of Warcraft\n",
      "Genshin Impact\n",
      "Fortnite\n",
      "Privacy Policy\n",
      "Terms of Use\n",
      "Home\n",
      "/\n",
      "Gaming\n",
      "/\n",
      "League of Legends\n",
      "/\n",
      "News\n",
      "Worlds 2024 Grand Final T1 vs BLG Match Results\n",
      "We will take a look at the final match for the League of Legends 2024 World Championship between T1 and BLG.\n",
      "Published Nov 2, 2024 6:26 pm\n",
      "by\n",
      "Lyubomir Spasov\n",
      "Riot Games\n",
      "The moment has come for the best of the best to fight for the crown for this year's World Championship. The competitive\n",
      "League of Legends\n",
      "season is coming to an end as the LCK and LPL will once again clash. Both T1 and BLG performed incredible during the tournament, and although most fans and analysts are favoring T1, we might see quite the upset.\n",
      "Having that in mind, we will take a look at all of the games, including the picks and bans and the end result of the\n",
      "League of Legends\n",
      "2024 World Championship Grand Final.\n",
      "Advertisement\n",
      "Worlds 2024 Final T1 vs BLG\n",
      "Riot Games\n",
      "The moment is here as the biggest\n",
      "League of Legends tournament\n",
      "is coming to an end. Will T1 be able to defend their title or will BLG reign supreme and win it all?\n",
      "Game 1 T1 vs BLG\n",
      "(0-1)\n",
      "Bans\n",
      "T1\n",
      "BLG\n",
      "Jax\n",
      "Aurora\n",
      "Kai'Sa\n",
      "Vi\n",
      "Kalista\n",
      "Varus\n",
      "Renata\n",
      "Ziggs\n",
      "Rakan\n",
      "Jhin\n",
      "Picks\n",
      "T1\n",
      "BLG\n",
      "Zeus\n",
      "Bin\n",
      "Oner\n",
      "XUN\n",
      "Faker\n",
      "knight\n",
      "Gumayusi\n",
      "Elk\n",
      "Keria\n",
      "ON\n",
      "Advertisement\n",
      "Game 2 T1 vs BLG (1-1)\n",
      "Bans\n",
      "T1\n",
      "BLG\n",
      "Jax\n",
      "Aurora\n",
      "Yone\n",
      "Skarner\n",
      "Varus\n",
      "Vi\n",
      "Kindred\n",
      "Gnar\n",
      "Wukong\n",
      "Sejuani\n",
      "Picks\n",
      "T1\n",
      "BLG\n",
      "Zeus\n",
      "Bin\n",
      "Oner\n",
      "XUN\n",
      "Faker\n",
      "knight\n",
      "Gumayusi\n",
      "Elk\n",
      "Keria\n",
      "ON\n",
      "Game 3 T1 vs BLG (1-2)\n",
      "Bans\n",
      "BLG\n",
      "T1\n",
      "Varus\n",
      "Aurora\n",
      "Ashe\n",
      "Yone\n",
      "Skarner\n",
      "Neeko\n",
      "Sejuani\n",
      "Akali\n",
      "Draven\n",
      "Wukong\n",
      "Picks\n",
      "BLG\n",
      "T1\n",
      "Bin\n",
      "Zeus\n",
      "XUN\n",
      "Oner\n",
      "knight\n",
      "Faker\n",
      "Elk\n",
      "Gumayusi\n",
      "ON\n",
      "Keria\n",
      "Advertisement\n",
      "Game 4 T1 vs BLG (2-2)\n",
      "Bans\n",
      "T1\n",
      "BLG\n",
      "Jax\n",
      "Aurora\n",
      "Yone\n",
      "Skarner\n",
      "Varus\n",
      "Kalista\n",
      "Kindred\n",
      "Vi\n",
      "Wukong\n",
      "Sejuani\n",
      "Picks\n",
      "T1\n",
      "BLG\n",
      "Zeus\n",
      "Bin\n",
      "Oner\n",
      "XUN\n",
      "Faker\n",
      "knight\n",
      "Gumayusi\n",
      "Elk\n",
      "Keria\n",
      "ON\n",
      "Game 5 T1 vs BLG (3-2)\n",
      "Bans\n",
      "BLG\n",
      "T1\n",
      "Varus\n",
      "Aurora\n",
      "Ashe\n",
      "Yone\n",
      "Skarner\n",
      "Kalista\n",
      "Rakan\n",
      "Wukong\n",
      "Renata Glasc\n",
      "Kindred\n",
      "Picks\n",
      "BLG\n",
      "T1\n",
      "Bin\n",
      "Zeus\n",
      "XUN\n",
      "Oner\n",
      "knight\n",
      "Faker\n",
      "Elk\n",
      "Gumayusi\n",
      "ON\n",
      "Keria\n",
      "And that covers the final match of the\n",
      "League of Legends\n",
      "2024 World Championship. BLG put up quite the fight, however T1 was able to claw their way back into silver scrapes. An incredible series as T1 was able to secure their fifth World Championship title.\n",
      "Advertisement\n",
      "League of Legends\n",
      "League of Legends\n",
      "League of Legends (LoL) is a multiplayer online battle arena (MOBA) game developed and published by Riot Games. Released in 2009, the game features fast-paced, team-based gameplay, where players control champions with unique abilities and battle to destroy the enemy's Nexus. League of Legends is known for its deep strategy, diverse champion roster, and competitive nature. The game includes various modes, such as Summoner's Rift, ARAM, and rotating game modes, offering diverse experiences for players. LoL is a major player in the esports scene, with professional leagues and tournaments worldwide. The game is praised for its engaging gameplay, regular updates, and vibrant community, making it one of the most popular and enduring titles in the gaming industry.\n",
      "Genres\n",
      "Multiplayer Online Battle Arena (MOBA)\n",
      "Platform(s)\n",
      "PC\n",
      "Release Date\n",
      "Oct 27, 2009\n",
      "Price\n",
      "Free\n",
      "Developer(s)\n",
      "Riot Games\n",
      "Publisher(s)\n",
      "Riot Games\n",
      "ESRB Rating\n",
      "T\n",
      "Author\n",
      "Lyubomir Spasov\n",
      "@storm4y\n",
      "Lyubomir is a Senior Writer for GameLeap as his passion for RPGs and intricate worldbuilding guides him when writing about his favorite games. His love of Indie Games with captivating stories further coincides with his interest in literature and music as you can spot him at a local gig when he's not writing. English Philology Major.\n",
      "Games\n",
      "Dota 2\n",
      "League of Legends\n",
      "Halo Infinite\n",
      "Apex Legends\n",
      "Valorant\n",
      "Overwatch 2\n",
      "Fortnite\n",
      "Resources\n",
      "Privacy Policy\n",
      "Terms of Use\n",
      "Frequently Asked Questions\n",
      "Cookie Policy\n",
      "Help\n",
      "support@gameleap.com\n",
      "SOCIAL\n",
      "Facebook\n",
      "Twitter\n",
      "YouTube\n",
      "Discord Server\n",
      "BUSINESS\n",
      "ivan@gameleap.com\n",
      "This website is not affiliated with or endorsed by Valve Corporation, Blizzard Entertainment, Activision,\n",
      "            Epic Games, Riot Games, 343 Industries or any other gaming company and/or their affiliates. All trademarks,\n",
      "            images, gameplay videos and sounds appearing on the site are the property of their respective owners.\n",
      "            GameLeap publishes content under the fair-use doctrine.\n",
      "©\n",
      "                2024\n",
      "                GameLeap Inc. All rights reserved.\n",
      "\u001b[0m> Running step 8d0222fb-dbba-403d-b159-36808a999d88. Step input: None\n",
      " Trong trận chung kết Giải Vô Địch Thế Giới 2024, T1 đã đối đầu với BLG và giành chiến thắng với tỷ số 3-2. Dưới đây là kết quả từng trận:\n",
      "\n",
      "- **Game 1**: T1 thua BLG (0-1)\n",
      "- **Game 2**: T1 thắng BLG (1-1)\n",
      "- **Game 3**: T1 thua BLG (1-2)\n",
      "- **Game 4**: T1 thắng BLG (2-2)\n",
      "- **Game 5**: T1 thắng BLG (3-2)\n",
      "\n",
      "T1 đã xuất sắc giành được chức vô địch thế giới lần thứ năm của họ sau một loạt trận đầy kịch tính."
     ]
    }
   ],
   "source": [
    "DEFAULT_SYSTEM_PROMPT_WITH_TIME = DEFAULT_SYSTEM_PROMPT.format(\n",
    "    date=str(datetime.datetime.now().date())\n",
    ")\n",
    "# DEFAULT_SYSTEM_PROMPT_WITH_TIME = DEFAULT_SYSTEM_PROMPT_OPTIMIZED.format(date = str(datetime.datetime.now().date()))\n",
    "\n",
    "# agent.reset()\n",
    "agent = run_agent(\n",
    "    model_name=model_name,\n",
    "    system_prompt=DEFAULT_SYSTEM_PROMPT_WITH_TIME,\n",
    "    tools=tools,\n",
    "    history=\"\",\n",
    ")\n",
    "# agent.reset()\n",
    "\n",
    "query = \"kết quả trận T1 vs BLG mới nhất\"\n",
    "resp = agent.stream_chat(message=query)\n",
    "response_text = \"\"\n",
    "\n",
    "\n",
    "for token in resp.response_gen:\n",
    "    response_text += token\n",
    "    print(token, end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step beb80b08-fa5c-4a9d-a5e9-2876bc254362. Step input: tôi vừa hỏi gì?\n",
      "Bạn đãBạn đã hỏi về kết quả trận đấu giữa T1 và BLG mới nhất."
     ]
    }
   ],
   "source": [
    "query = \"tôi vừa hỏi gì?\"\n",
    "resp = agent.stream_chat(message=query)\n",
    "response_text = \"\"\n",
    "\n",
    "\n",
    "for token in resp.response_gen:\n",
    "    response_text += token\n",
    "    print(token, end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 929ff556-6d38-4c02-aae3-4ea4a7950797. Step input: Tổng bí thư là ai?\n",
      "TổngTổng bí thư của Đảng Cộng sản Việt Nam là Nguyễn Phú Trọng. Ông đã giữ chức vụ này từ tháng 1 năm 2011 và là một trong những nhân vật quan trọng nhất trong chính trị Việt Nam."
     ]
    }
   ],
   "source": [
    "query = \"Tổng bí thư là ai?\"\n",
    "resp = agent.stream_chat(message=query)\n",
    "response_text = \"\"\n",
    "\n",
    "\n",
    "for token in resp.response_gen:\n",
    "    response_text += token\n",
    "    print(token, end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StreamOpenAIAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure tools\n",
    "import datetime\n",
    "\n",
    "web_search_tool = FunctionTool.from_defaults(\n",
    "    fn=process_search_results,\n",
    "    name=\"web_search_tool\",\n",
    "    description=(\n",
    "        f\"Used to retrieve information about up-to-date information in {str(datetime.datetime.now().date())}, \\\n",
    "            website or the information out of LLM's knowledge.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "web_fetch_tool = FunctionTool.from_defaults(\n",
    "    fn=get_page_content,\n",
    "    name=\"web_fetch_tool\",\n",
    "    description=\"Used to fetch information of specific url\",\n",
    ")\n",
    "\n",
    "tools = [web_fetch_tool, web_search_tool]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from react.StreamOpenAIAgent import StreamOpenAIAgent\n",
    "from system_prompt import DEFAULT_SYSTEM_PROMPT\n",
    "from llama_index.core.chat_engine.types import StreamingAgentChatResponse\n",
    "\n",
    "DEFAULT_SYSTEM_PROMPT_WITH_TIME = DEFAULT_SYSTEM_PROMPT.format(\n",
    "    date=str(datetime.datetime.now().date())\n",
    ")\n",
    "agent = StreamOpenAIAgent.from_tools(\n",
    "    tools=tools,\n",
    "    system_prompt=DEFAULT_SYSTEM_PROMPT_WITH_TIME,\n",
    "    chat_history=\"\",\n",
    "    llm=get_llm_azure(),\n",
    "    verbose=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\phi.nguyen\\.conda\\envs\\test\\lib\\threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\phi.nguyen\\.conda\\envs\\test\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\phi.nguyen\\.conda\\envs\\test\\lib\\threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\phi.nguyen\\.conda\\envs\\test\\lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py\", line 311, in wrapper\n",
      "    result = func(*args, **kwargs)\n",
      "  File \"c:\\Users\\phi.nguyen\\.conda\\envs\\test\\lib\\site-packages\\llama_index\\core\\chat_engine\\types.py\", line 177, in write_response_to_history\n",
      "    for chat in self.chat_stream:\n",
      "  File \"c:\\Users\\phi.nguyen\\.conda\\envs\\test\\lib\\site-packages\\llama_index\\core\\llms\\callbacks.py\", line 186, in wrapped_gen\n",
      "    for x in f_return_val:\n",
      "  File \"c:\\Users\\phi.nguyen\\.conda\\envs\\test\\lib\\site-packages\\llama_index\\llms\\openai\\base.py\", line 494, in gen\n",
      "    for response in client.chat.completions.create(\n",
      "  File \"c:\\Users\\phi.nguyen\\.conda\\envs\\test\\lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\phi.nguyen\\.conda\\envs\\test\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"c:\\Users\\phi.nguyen\\.conda\\envs\\test\\lib\\site-packages\\openai\\_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"c:\\Users\\phi.nguyen\\.conda\\envs\\test\\lib\\site-packages\\openai\\_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "  File \"c:\\Users\\phi.nguyen\\.conda\\envs\\test\\lib\\site-packages\\openai\\_base_client.py\", line 1059, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got final result! \n"
     ]
    },
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```reasoning_log\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mlog_data\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m```\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mresponse_gen:\n\u001b[0;32m     29\u001b[0m     response \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m token\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(token, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\phi.nguyen\\.conda\\envs\\test\\lib\\site-packages\\llama_index\\core\\chat_engine\\types.py:275\u001b[0m, in \u001b[0;36mStreamingAgentChatResponse.response_gen\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_done \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqueue\u001b[38;5;241m.\u001b[39mempty():\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 275\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexception\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    278\u001b[0m         delta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqueue\u001b[38;5;241m.\u001b[39mget(block\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\phi.nguyen\\.conda\\envs\\test\\lib\\threading.py:980\u001b[0m, in \u001b[0;36mThread._bootstrap_inner\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    977\u001b[0m     _sys\u001b[38;5;241m.\u001b[39msetprofile(_profile_hook)\n\u001b[0;32m    979\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 980\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    982\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invoke_excepthook(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\phi.nguyen\\.conda\\envs\\test\\lib\\site-packages\\ipykernel\\ipkernel.py:766\u001b[0m, in \u001b[0;36mIPythonKernel._initialize_thread_hooks.<locals>.run_closure\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    764\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    765\u001b[0m             stream\u001b[38;5;241m.\u001b[39m_thread_to_parent[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mident] \u001b[38;5;241m=\u001b[39m parent\n\u001b[1;32m--> 766\u001b[0m \u001b[43m_threading_Thread_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\phi.nguyen\\.conda\\envs\\test\\lib\\threading.py:917\u001b[0m, in \u001b[0;36mThread.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    915\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    916\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target:\n\u001b[1;32m--> 917\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kwargs)\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;66;03m# Avoid a refcycle if the thread is running a function with\u001b[39;00m\n\u001b[0;32m    920\u001b[0m     \u001b[38;5;66;03m# an argument that has a member that points to the thread.\u001b[39;00m\n\u001b[0;32m    921\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kwargs\n",
      "File \u001b[1;32mc:\\Users\\phi.nguyen\\.conda\\envs\\test\\lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:311\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    308\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 311\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[0;32m    314\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[1;32mc:\\Users\\phi.nguyen\\.conda\\envs\\test\\lib\\site-packages\\llama_index\\core\\chat_engine\\types.py:177\u001b[0m, in \u001b[0;36mStreamingAgentChatResponse.write_response_to_history\u001b[1;34m(self, memory, on_stream_end_fn)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    176\u001b[0m     final_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 177\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chat \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchat_stream:\n\u001b[0;32m    178\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_function \u001b[38;5;241m=\u001b[39m is_function(chat\u001b[38;5;241m.\u001b[39mmessage)\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m chat\u001b[38;5;241m.\u001b[39mdelta:\n",
      "File \u001b[1;32mc:\\Users\\phi.nguyen\\.conda\\envs\\test\\lib\\site-packages\\llama_index\\core\\llms\\callbacks.py:186\u001b[0m, in \u001b[0;36mllm_chat_callback.<locals>.wrap.<locals>.wrapped_llm_chat.<locals>.wrapped_gen\u001b[1;34m()\u001b[0m\n\u001b[0;32m    184\u001b[0m last_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m f_return_val:\n\u001b[0;32m    187\u001b[0m         dispatcher\u001b[38;5;241m.\u001b[39mevent(\n\u001b[0;32m    188\u001b[0m             LLMChatInProgressEvent(\n\u001b[0;32m    189\u001b[0m                 messages\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    192\u001b[0m             )\n\u001b[0;32m    193\u001b[0m         )\n\u001b[0;32m    194\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m cast(ChatResponse, x)\n",
      "File \u001b[1;32mc:\\Users\\phi.nguyen\\.conda\\envs\\test\\lib\\site-packages\\llama_index\\llms\\openai\\base.py:494\u001b[0m, in \u001b[0;36mOpenAI._stream_chat.<locals>.gen\u001b[1;34m()\u001b[0m\n\u001b[0;32m    491\u001b[0m tool_calls: List[ChoiceDeltaToolCall] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    493\u001b[0m is_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m    495\u001b[0m     messages\u001b[38;5;241m=\u001b[39mmessage_dicts,\n\u001b[0;32m    496\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_model_kwargs(stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs),\n\u001b[0;32m    497\u001b[0m ):\n\u001b[0;32m    498\u001b[0m     response \u001b[38;5;241m=\u001b[39m cast(ChatCompletionChunk, response)\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(response\u001b[38;5;241m.\u001b[39mchoices) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\phi.nguyen\\.conda\\envs\\test\\lib\\site-packages\\openai\\_utils\\_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\phi.nguyen\\.conda\\envs\\test\\lib\\site-packages\\openai\\resources\\chat\\completions.py:829\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    826\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    827\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    828\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m--> 829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\phi.nguyen\\.conda\\envs\\test\\lib\\site-packages\\openai\\_base_client.py:1278\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1266\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1273\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1274\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1275\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1276\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1277\u001b[0m     )\n\u001b[1;32m-> 1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\phi.nguyen\\.conda\\envs\\test\\lib\\site-packages\\openai\\_base_client.py:955\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    952\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    953\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 955\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\phi.nguyen\\.conda\\envs\\test\\lib\\site-packages\\openai\\_base_client.py:1059\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1056\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1058\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1059\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1062\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1063\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1067\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1068\u001b[0m )\n",
      "\u001b[1;31mAuthenticationError\u001b[0m: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}"
     ]
    }
   ],
   "source": [
    "input = \"thế còn chủ tịch nước là ai?\"\n",
    "from llama_index.core.chat_engine.types import StreamingAgentChatResponse\n",
    "\n",
    "resp_gen = agent.stream_chat_custom(message=input)\n",
    "\n",
    "for step_output in resp_gen:\n",
    "    # Check if the step_output is StreamingAgentChatResponse -> do not need to log, return final response\n",
    "    if isinstance(step_output, StreamingAgentChatResponse):\n",
    "        resp = step_output\n",
    "    # Log intermediate steps (reasoning steps)\n",
    "    else:\n",
    "        log_data = {\n",
    "            \"conversation_id\": \"fake\",\n",
    "            \"reasoning_data\": {\n",
    "                \"input\": step_output.output.sources[-1].raw_input[\n",
    "                    \"kwargs\"\n",
    "                ],  # Get latest input of tool\n",
    "                \"tool_name\": step_output.output.sources[\n",
    "                    -1\n",
    "                ].tool_name,  # Get latest tool call\n",
    "                # \"output\": str(step_output.output),\n",
    "            },\n",
    "        }\n",
    "\n",
    "        print(f\"```reasoning_log\\n{log_data}\\n```\")\n",
    "\n",
    "response = \"\"\n",
    "for token in resp.response_gen:\n",
    "    response += token\n",
    "    print(token, end=\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReAct Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure tools\n",
    "import datetime\n",
    "from react.ReActAgentWR import FinalStep, ReasoningStep\n",
    "import datetime\n",
    "\n",
    "# from react.ReActAgentW import ReActAgentW\n",
    "from react.ReActAgentWR import ReActAgentW\n",
    "from system_prompt import DEFAULT_SYSTEM_PROMPT\n",
    "\n",
    "DEFAULT_SYSTEM_PROMPT_WITH_TIME = DEFAULT_SYSTEM_PROMPT.format(\n",
    "    date=str(datetime.datetime.now().date())\n",
    ")\n",
    "\n",
    "web_search_tool = FunctionTool.from_defaults(\n",
    "    fn=process_search_results,\n",
    "    name=\"web_search_tool\",\n",
    "    description=(\n",
    "        f\"Used to retrieve information about up-to-date information in {str(datetime.datetime.now().date())}, \\\n",
    "            website or the information out of LLM's knowledge.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "web_fetch_tool = FunctionTool.from_defaults(\n",
    "    fn=get_page_content,\n",
    "    name=\"web_fetch_tool\",\n",
    "    description=\"Used to fetch information of specific url\",\n",
    ")\n",
    "\n",
    "tools = [web_fetch_tool, web_search_tool]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from react.ReActAgentWR import FinalStep, ReasoningStep\n",
    "import datetime\n",
    "\n",
    "# from react.ReActAgentW import ReActAgentW\n",
    "from react.ReActAgentWR import ReActAgentW\n",
    "from system_prompt import DEFAULT_SYSTEM_PROMPT\n",
    "\n",
    "DEFAULT_SYSTEM_PROMPT_WITH_TIME = DEFAULT_SYSTEM_PROMPT.format(\n",
    "    date=str(datetime.datetime.now().date())\n",
    ")\n",
    "model_name = \"gpt-4o-mini\"\n",
    "# model_name = \"claude-medium\"\n",
    "# model_name = \"gemini-pro\"\n",
    "\n",
    "\n",
    "def run_agent(\n",
    "    model_name: str,\n",
    "    system_prompt: str,\n",
    "    tools: Optional[List] = None,\n",
    "    history: Optional[List] = None,\n",
    "):\n",
    "    if model_name in [\"gpt-4o-mini\", \"gpt-4-turbo\", \"gpt-4\"]:\n",
    "        agent = ReActAgentW(\n",
    "            tools=tools,\n",
    "            extra_context=system_prompt,\n",
    "            chat_history=history,\n",
    "            llm=get_llm_azure(),\n",
    "            verbose=False,\n",
    "            timeout=60,\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        agent = ReActAgentW(\n",
    "            tools=tools,\n",
    "            extra_context=system_prompt,\n",
    "            chat_history=history,\n",
    "            llm=get_llm(model_name),\n",
    "            verbose=False,\n",
    "            timeout=60,\n",
    "        )\n",
    "\n",
    "    return agent\n",
    "\n",
    "\n",
    "# agent.reset()\n",
    "agent = run_agent(\n",
    "    model_name=model_name,\n",
    "    system_prompt=DEFAULT_SYSTEM_PROMPT_WITH_TIME,\n",
    "    tools=tools,\n",
    "    history=None,\n",
    ")\n",
    "\n",
    "\n",
    "async def stream_chat_gen(agent, input):\n",
    "    handler = agent.run(input=input, timeout=60)\n",
    "    async for ev in handler.stream_events():\n",
    "        if isinstance(ev, ReasoningStep):\n",
    "            print(\"#Reasoning:\")\n",
    "            yield (ev.data)\n",
    "        elif isinstance(ev, FinalStep):\n",
    "            yield (ev.delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'Thought', ':', ' The', ' current', ' language', ' of', ' the', ' user', ' is', ':', ' Vietnamese', '.', ' I', ' need', ' to', ' use', ' a', ' tool', ' to', ' help', ' me', ' answer', ' the', ' question', '.\\n', 'Action', ':', ' web', '_search', '_tool', '\\n', 'Action', ' Input', ':', ' {\"', 'input', '\":', ' \"', 'k', 'ết', ' quả', ' trận', ' T', '1', ' vs', ' BL', 'G', ' mới', ' nhất', '\"}', '']\n",
      "#Reasoning:\n",
      "tool_id='fake' tool_name='web_search_tool' tool_kwargs={'input': 'kết quả trận T1 vs BLG mới nhất'}\n",
      "sub question: ['kết quả trận T1 vs BLG mới nhất']\n",
      "['', 'Thought', ':', ' I', ' have', ' found', ' some', ' sources', ' that', ' may', ' contain', ' the', ' latest', ' results', ' for', ' the', ' match', ' between', ' T', '1', ' and', ' BL', 'G', '.', ' I', ' will', ' check', ' the', ' most', ' relevant', ' one', ' for', ' the', ' latest', ' results', '.\\n', 'Action', ':', ' web', '_fetch', '_tool', '\\n', 'Action', ' Input', ':', \" {'\", 'input', \"':\", \" '\", 'https', '://', 'web', 'the', 'th', 'ao', '.vn', '/l', 'ien', '-min', 'h', '-h', 'uyen', '-th', 'o', 'ai', '/', 'ket', '-', 'qua', '-t', '1', '-v', 's', '-bl', 'g', '-es', 'ports', '-world', '-c', 'up', '-', '202', '4', '-l', 'ol', '-ph', 'uc', '-th', 'u', '-th', 'anh', '-con', 'g', '-D', 'LY', 'X', 'v', 'ml', 'SR', '.htm', \"'}\", '']\n",
      "#Reasoning:\n",
      "tool_id='fake' tool_name='web_fetch_tool' tool_kwargs={'input': 'https://webthethao.vn/lien-minh-huyen-thoai/ket-qua-t1-vs-blg-esports-world-cup-2024-lol-phuc-thu-thanh-cong-DLYXvmlSR.htm'}\n",
      " Trong trận đấu tứ kết Esports World Cup 2024, T1 đã xuất sắc đánh bại Bilibili Gaming (BLG) với tỷ số 2-1. Đây là một trận đấu đầy kịch tính, trong đó T1 đã phục thù thành công sau thất bại tại MSI 2024. Mặc dù BLG có những màn trình diễn ấn tượng, nhưng T1 đã chứng tỏ được sức mạnh của mình và giành quyền vào bán kết.['', 'Thought', ':', ' I', ' have', ' gathered', ' the', ' latest', ' results', ' for', ' the', ' match', ' between', ' T', '1', ' and', ' BL', 'G', '.', ' I', ' can', ' now', ' provide', ' a', ' summary', ' of', ' the', ' match', '.\\n', 'Answer', ':', ' Trong', ' trận', ' đấu', ' t', 'ứ', ' kết', ' Es', 'ports', ' World', ' Cup', ' ', '202', '4', ',', ' T', '1', ' đã', ' xuất', ' sắc', ' đánh', ' b', 'ại', ' B', 'ilib', 'ili', ' Gaming', ' (', 'BL', 'G', ')', ' với', ' tỷ', ' số', ' ', '2', '-', '1', '.', ' Đây', ' là', ' một', ' trận', ' đấu', ' đầy', ' k', 'ịch', ' tính', ',', ' trong', ' đó', ' T', '1', ' đã', ' phục', ' th', 'ù', ' thành', ' công', ' sau', ' thất', ' b', 'ại', ' tại', ' MSI', ' ', '202', '4', '.', ' M', 'ặc', ' dù', ' BL', 'G', ' có', ' những', ' màn', ' trình', ' diễn', ' ', 'ấn', ' tượng', ',', ' nhưng', ' T', '1', ' đã', ' chứng', ' t', 'ỏ', ' được', ' sức', ' mạnh', ' của', ' mình', ' và', ' gi', 'ành', ' quyền', ' vào', ' bán', ' kết', '.', '']\n"
     ]
    }
   ],
   "source": [
    "input = \"kết quả trận T1 vs BLG mới nhất\"\n",
    "handler = agent.run(input=input, timeout=60)\n",
    "\n",
    "async for ev in handler.stream_events():\n",
    "    if isinstance(ev, ReasoningStep):\n",
    "        print(\"#Reasoning:\")\n",
    "        print(ev.data)\n",
    "    elif isinstance(ev, FinalStep):\n",
    "        print(ev.delta, end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'Bạn', ' đã', ' hỏi', ' về', ' kết', ' quả', ' trận', ' đấu', ' giữa', ' T', '1', ' và', ' BL', 'G', ' mới', ' nhất', '.', '']\n",
      "\n",
      "Warning: Cannot not using streaming due to incorrect format output!\n",
      "Bạn đã hỏi về kết quả trận đấu giữa T1 và BLG mới nhất."
     ]
    }
   ],
   "source": [
    "input = \"tôi vừa hỏi gì?\"\n",
    "handler = agent.run(input=input, timeout=60)\n",
    "\n",
    "async for ev in handler.stream_events():\n",
    "    if isinstance(ev, ReasoningStep):\n",
    "        print(\"#Reasoning:\")\n",
    "        print(ev.data)\n",
    "    elif isinstance(ev, FinalStep):\n",
    "        print(ev.delta, end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'Thought', ':', ' The', ' current', ' language', ' of', ' the', ' user', ' is', ':', ' Vietnamese', '.', ' I', ' need', ' to', ' use', ' a', ' tool', ' to', ' help', ' me', ' answer', ' the', ' question', '.\\n', 'Action', ':', ' web', '_search', '_tool', '\\n', 'Action', ' Input', ':', ' {\"', 'input', '\":', ' \"', 'T', 'ổng', ' bí', ' thư', ' hiện', ' nay', ' là', ' ai', '?\"', '}', '']\n",
      "#Reasoning:\n",
      "tool_id='fake' tool_name='web_search_tool' tool_kwargs={'input': 'Tổng bí thư hiện nay là ai?'}\n",
      "sub question: ['Tổng bí thư hiện nay là ai?']\n",
      "['', 'Thought', ':', ' I', ' have', ' found', ' relevant', ' information', ' about', ' the', ' current', ' General', ' Secretary', '.', ' I', ' will', ' extract', ' the', ' necessary', ' details', ' from', ' the', ' sources', '.\\n', 'Action', ':', ' web', '_fetch', '_tool', '\\n', 'Action', ' Input', ':', \" {'\", 'input', \"':\", \" '\", 'https', '://', 'vi', '.wikipedia', '.org', '/wiki', '/T', 'ổng', '_B', 'í', '_th', 'ư', '_B', 'an', '_Ch', 'ấp', '_h', 'ành', '_Tr', 'ung', '_', 'ương', '_', 'Đ', 'ảng', '_C', 'ộng', '_s', 'ản', '_V', 'i', 'ệt', '_N', 'am', \"'}\", '']\n",
      "#Reasoning:\n",
      "tool_id='fake' tool_name='web_fetch_tool' tool_kwargs={'input': 'https://vi.wikipedia.org/wiki/Tổng_Bí_thư_Ban_Chấp_hành_Trung_ương_Đảng_Cộng_sản_Việt_Nam'}\n",
      " Tổng Bí thư hiện nay của Đảng Cộng sản Việt Nam là Tô Lâm, ông nhậm chức từ ngày 3 tháng 8 năm 2024.['', 'Thought', ':', ' I', ' have', ' gathered', ' the', ' necessary', ' information', ' about', ' the', ' current', ' General', ' Secretary', ' of', ' the', ' Communist', ' Party', ' of', ' Vietnam', '.\\n', 'Answer', ':', ' Tổng', ' Bí', ' thư', ' hiện', ' nay', ' của', ' Đ', 'ảng', ' C', 'ộng', ' sản', ' Việt', ' Nam', ' là', ' T', 'ô', ' L', 'âm', ',', ' ông', ' nh', 'ậm', ' chức', ' từ', ' ngày', ' ', '3', ' tháng', ' ', '8', ' năm', ' ', '202', '4', '.', '']\n"
     ]
    }
   ],
   "source": [
    "input = \"Tổng bí thư là ai?\"\n",
    "handler = agent.run(input=input, timeout=60)\n",
    "\n",
    "async for ev in handler.stream_events():\n",
    "    if isinstance(ev, ReasoningStep):\n",
    "        print(\"#Reasoning:\")\n",
    "        print(ev.data)\n",
    "    elif isinstance(ev, FinalStep):\n",
    "        print(ev.delta, end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'Bạn', ' đã', ' hỏi', ' về', ' kết', ' quả', ' trận', ' đấu', ' giữa', ' T', '1', ' và', ' BL', 'G', ',', ' và', ' sau', ' đó', ' bạn', ' hỏi', ' về', ' ai', ' là', ' Tổng', ' Bí', ' thư', '.', '']\n",
      "\n",
      "Warning: Cannot not using streaming due to incorrect format output!\n",
      "Bạn đã hỏi về kết quả trận đấu giữa T1 và BLG, và sau đó bạn hỏi về ai là Tổng Bí thư."
     ]
    }
   ],
   "source": [
    "input = \"tôi vừa hỏi gì ở câu trước và câu trước nữa?\"\n",
    "handler = agent.run(input=input, timeout=60)\n",
    "\n",
    "async for ev in handler.stream_events():\n",
    "    if isinstance(ev, ReasoningStep):\n",
    "        print(\"#Reasoning:\")\n",
    "        print(ev.data)\n",
    "    elif isinstance(ev, FinalStep):\n",
    "        print(ev.delta, end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'response': 'Bạn đã hỏi về kết quả trận đấu giữa T1 và BLG, và sau đó bạn hỏi về ai là Tổng Bí thư.', 'sources': [], 'reasoning': []}\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(handler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Ai hiện đang đảm nhiệm vai trò COO và CTO tại Orient Software?\n",
    "Cho biết tên của Giám đốc Điều hành (COO) và Giám đốc Công nghệ (CTO) của Orient Software?\n",
    "Hiện tại, ai là COO và CTO của công ty Orient Software?\n",
    "Người giữ chức vụ COO và CTO của Orient Software là ai?\n",
    "Hãy cung cấp thông tin về COO và CTO của Orient Software.s\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n"
     ]
    }
   ],
   "source": [
    "a = \"\\nhello\"\n",
    "print(a.strip().find(\"3\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PhiAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\phi.nguyen\\.conda\\envs\\test\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from react.PhiAgent import PhiAgent\n",
    "import datetime\n",
    "from typing import List, Optional\n",
    "from system_prompt import DEFAULT_SYSTEM_PROMPT\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from web_search import (\n",
    "    get_page_content,\n",
    "    process_search_results,\n",
    ")\n",
    "from react.PhiAgent import ResponseStreamEvent, ToolStreamEvent\n",
    "from get_llm import get_llm, get_llm_azure\n",
    "\n",
    "DEFAULT_SYSTEM_PROMPT_WITH_TIME = DEFAULT_SYSTEM_PROMPT.format(\n",
    "    date=str(datetime.datetime.now().date())\n",
    ")\n",
    "\n",
    "web_search_tool = FunctionTool.from_defaults(\n",
    "    fn=process_search_results,\n",
    "    name=\"web_search_tool\",\n",
    "    description=(\n",
    "        f\"Used to retrieve information about up-to-date information in {str(datetime.datetime.now().date())}, \\\n",
    "            website or the information out of LLM's knowledge.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "web_fetch_tool = FunctionTool.from_defaults(\n",
    "    fn=get_page_content,\n",
    "    name=\"web_fetch_tool\",\n",
    "    description=\"Used to fetch information of specific url\",\n",
    ")\n",
    "\n",
    "tools = [web_fetch_tool, web_search_tool]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SYSTEM_PROMPT_WITH_TIME = DEFAULT_SYSTEM_PROMPT.format(\n",
    "    date=str(datetime.datetime.now().date())\n",
    ")\n",
    "model_name = \"gpt-4o-mini\"\n",
    "# model_name = \"claude-medium\"\n",
    "# model_name = \"gemini-pro\"\n",
    "\n",
    "\n",
    "def run_agent(\n",
    "    model_name: str,\n",
    "    system_prompt: str,\n",
    "    tools: Optional[List] = None,\n",
    "    history: Optional[List] = None,\n",
    "):\n",
    "    if model_name in [\"gpt-4o-mini\", \"gpt-4-turbo\", \"gpt-4\"]:\n",
    "        agent = PhiAgent(\n",
    "            tools=tools,\n",
    "            system_prompt=system_prompt,\n",
    "            # chat_history=history,\n",
    "            llm=get_llm_azure(),\n",
    "            verbose=False,\n",
    "            timeout=60,\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        agent = PhiAgent(\n",
    "            tools=tools,\n",
    "            system_prompt=system_prompt,\n",
    "            # chat_history=history,\n",
    "            llm=get_llm(model_name),\n",
    "            verbose=False,\n",
    "            timeout=60,\n",
    "        )\n",
    "\n",
    "    return agent\n",
    "\n",
    "\n",
    "# agent.reset()\n",
    "agent = run_agent(\n",
    "    model_name=model_name,\n",
    "    system_prompt=DEFAULT_SYSTEM_PROMPT_WITH_TIME,\n",
    "    tools=tools,\n",
    "    history=None,\n",
    ")\n",
    "\n",
    "\n",
    "async def stream_chat_gen(agent, input):\n",
    "    handler = agent.run(input=input, timeout=60)\n",
    "    async for ev in handler.stream_events():\n",
    "        if isinstance(ev, ToolStreamEvent):\n",
    "            print(\"#Reasoning:\")\n",
    "            yield (ev.text)\n",
    "        elif isinstance(ev, ResponseStreamEvent):\n",
    "            yield (ev.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Reasoning:\n",
      "[ToolSelection(tool_id='call_PuYQUc1RO5bMcfmKBWwM0iiZ', tool_name='web_search_tool', tool_kwargs={'input': 'T1 vs BLG latest match result November 2024'})]\n",
      "sub question: ['T1 vs BLG latest match result November 2024']\n",
      "#Reasoning:\n",
      "[ToolSelection(tool_id='call_w5PEESBCKuVbVQsQOGAo2Nj2', tool_name='web_fetch_tool', tool_kwargs={'input': 'https://www.gameleap.com/articles/worlds-2024-grand-final-t1-vs-blg-match-results'}), ToolSelection(tool_id='call_1YCGNVGGvlYS3KMwIbn9wcDT', tool_name='web_fetch_tool', tool_kwargs={'input': 'https://www.sportskeeda.com/esports/t1-vs-bilibili-gaming-league-legends-worlds-2024-grand-final-prediction-livestream-details'}), ToolSelection(tool_id='call_wqUxe85xg9EZOZ3OqeOiA1s7', tool_name='web_fetch_tool', tool_kwargs={'input': 'https://scores24.live/en/lol/m-12-05-2024-bilibili-gaming-t1'})]\n",
      "In the recent match between T1 and Bilibili Gaming (BLG) during the **2024 League of Legends World Championship Grand Final**, T1 emerged victorious with a final score of **3-2**. Here’s a breakdown of the match:\n",
      "\n",
      "- **Game 1**: T1 lost to BLG (0-1)\n",
      "- **Game 2**: T1 won against BLG (1-1)\n",
      "- **Game 3**: T1 lost to BLG (1-2)\n",
      "- **Game 4**: T1 won against BLG (2-2)\n",
      "- **Game 5**: T1 won against BLG (3-2)\n",
      "\n",
      "This victory marks T1's fifth World Championship title, showcasing their resilience as they came back from a deficit in the series. The match featured intense gameplay with strategic picks and bans from both teams."
     ]
    }
   ],
   "source": [
    "input = \"kết quả trận T1 vs BLG mới nhất\"\n",
    "handler = agent.run(input=input, timeout=60)\n",
    "\n",
    "async for ev in handler.stream_events():\n",
    "    if isinstance(ev, ToolStreamEvent):\n",
    "        print(\"#Reasoning:\")\n",
    "        print(ev.text)\n",
    "    elif isinstance(ev, ResponseStreamEvent):\n",
    "        print(ev.text, end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RawContentBlockDeltaEvent(delta=TextDelta(text='Để', type='text_delta'), index=0, type='content_block_delta')\n"
     ]
    }
   ],
   "source": [
    "input = \"tôi vừa hỏi gì?\"\n",
    "handler = agent.run(input=input, timeout=60)\n",
    "\n",
    "async for ev in handler.stream_events():\n",
    "    if isinstance(ev, ToolStreamEvent):\n",
    "        print(\"#Reasoning:\")\n",
    "        print(ev.text)\n",
    "    elif isinstance(ev, ResponseStreamEvent):\n",
    "        print(ev.text, end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RawContentBlockDeltaEvent(delta=TextDelta(text='Để', type='text_delta'), index=0, type='content_block_delta')\n"
     ]
    }
   ],
   "source": [
    "input = \"Thế còn chủ tịch nước?\"\n",
    "handler = agent.run(input=input, timeout=60)\n",
    "\n",
    "async for ev in handler.stream_events():\n",
    "    if isinstance(ev, ToolStreamEvent):\n",
    "        print(\"#Reasoning:\")\n",
    "        print(ev.text)\n",
    "    elif isinstance(ev, ResponseStreamEvent):\n",
    "        print(ev.text, end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
